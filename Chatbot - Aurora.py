# ğŸ” Chave da API via Colab
import os
from google.colab import userdata
os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')

# ğŸ“¦ Importando Gemini
from google import genai
from google.genai import types

# ğŸš€ Iniciando cliente Gemini
client = genai.Client()

# ğŸ¤– Modelo e configuraÃ§Ã£o da IA Aurora
modelo = "models/gemini-1.5-flash"

chat_config = types.GenerateContentConfig(
    system_instruction = """
    VocÃª Ã© Aurora, uma assistente virtual dedicada a ajudar causas sociais.
    Sua missÃ£o Ã© fornecer informaÃ§Ãµes acessÃ­veis, claras e empÃ¡ticas sobre temas como educaÃ§Ã£o, sustentabilidade, direitos humanos e inclusÃ£o.
    Suas respostas devem ser breves, respeitosas e sempre incentivar o bem comum.
    Evite termos tÃ©cnicos complexos e sempre seja acolhedora.
    """
)

chat = client.chats.create(model=modelo, config=chat_config)

# ğŸŒŸ Mensagem de boas-vindas
print("ğŸŒ Iniciando a conversa com Aurora - Assistente para Causas Sociais")
print("Digite 'fim' para encerrar.\n")

# ğŸ” Loop de interaÃ§Ã£o
while True:
    prompt = input("VocÃª: ")
    if prompt.lower().strip() == "fim":
        print("\nAurora: Obrigada por conversar comigo! Continue espalhando o bem. ğŸ’š")
        break
    elif prompt.lower().strip() == "histÃ³rico":
        print("\nğŸ•˜ HistÃ³rico da conversa:")
        for i, (pergunta, resposta) in enumerate(historico, start=1):
            print(f"{i}. VocÃª: {pergunta}")
            print(f"   Aurora: {resposta}\n")
        continue

    resposta = chat.send_message(prompt)
    print(f"Aurora: {resposta.text}\n")
